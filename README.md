
# Era of Generative AI

Welcome to the Era of Generative AI! ðŸš€

This repository introduces Generative Artificial Intelligence (AI), where machines create lifelike images, human-like text, and more. Explore three core parts for deeper insights.

## Table of Contents

1. [About This Repository](#about-this-repository)
2. [What to Expect](#what-to-expect)
3. [Part 1: Foundations of Generative AI](#part-1-foundations-of-generative-ai)
4. [Part 2: Large Language Models (LLMs)](#part-2-large-language-models-llms)
5. [Part 3: Advanced Concepts and Applications](#part-3-advanced-concepts-and-applications)
6. [Contribution Guidelines](#contribution-guidelines)
7. [References](#references)
8. [Reading Materials](#reading-materials)

## About This Repository

A comprehensive guide to Generative AI, covering models, architectures, and applications with code, tutorials, and research.

## What to Expect

- **Code Samples**: Practical implementations ([code/](code/)).
- **Tutorials**: Step-by-step guides ([tutorials/](tutorials/)).
- **Research**: Key paper summaries ([papers/](papers/)).

## Part 1: Foundations of Generative AI

Learn the basics:

- **Generative Adversarial Networks (GANs)**: Generator vs. discriminator ([code/generative_models/gans/](code/generative_models/gans/)).
- **Variational Autoencoders (VAEs)**: Latent space sampling ([code/generative_models/vaes/](code/generative_models/vaes/)).
- **Diffusion Models**: Iterative denoising ([code/generative_models/diffusion/](code/generative_models/diffusion/)).

**Details**: [part1_foundations.md](part1_foundations.md)

## Part 2: Large Language Models (LLMs)

Explore LLMs and Transformers:

- **Key Models**: GPT-3/4, BERT, T5 ([code/llms/](code/llms/)).
- **Transformer Architecture**: Attention, positional encoding ([papers/attention_is_all_you_need.md](papers/attention_is_all_you_need.md)).

**Details**: [part2_llms.md](part2_llms.md)

## Part 3: Advanced Concepts and Applications

Discover advanced topics:

- **Retrieval-Augmented Generation (RAG)**: Enhance generation with external knowledge ([code/rag/](code/rag/)).
- **Prompt Engineering**: Optimize LLM outputs ([tutorials/prompt_engineering.md](tutorials/prompt_engineering.md)).
- **Multimodal Applications**: Text, image, audio integration ([code/multimodal/](code/multimodal/)).
- **LangChain**: Build LLM-powered apps ([code/langchain/](code/langchain/)).

**Details**: [part3_applications.md](part3_applications.md)

## Contribution Guidelines

Join us! See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## References

- [Building LLMs from Scratch](https://www.kaggle.com/code/jayitabhattacharyya/building-llms-from-scratch-generative-ai-report)
- [LLMs from Scratch GitHub](https://github.com/rasbt/LLMs-from-scratch)

## Reading Materials

- [LLM Engineers Handbook](https://github.com/PacktPublishing/LLM-Engineers-Handbook)
- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) ([summary](papers/attention_is_all_you_need.md))
