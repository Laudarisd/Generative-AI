## Prompt Engineering: A Practical Example

We have already seen how LLMs work. For instance, ChatGPT, Claude, and many ther language needs proper prompt to get better output.

Our text prompt instructs the LLM's responses, so tweaking it can get our vastly differnt output. 

In this section, we will learn about `prompt engineering techniques` to real world  example. 



1. [Introduction](#introduction)
2. [Technologies Used](#technologies-used)





## Introduction

Prompt engineering is more than a buzzword. You can get vastly different output from an LLM when using different prompts. That may seem obvious when you consider that you get different output when you ask different questionsâ€”but it also applies to phrasing the same conceptual question differently. Prompt engineering means constructing your text input to the LLM using specific approaches.

You can think of prompts as arguments and the LLM as the function to which you pass these arguments. Different input means different output:



### References

[Python](https://realpython.com/practical-prompt-engineering/)